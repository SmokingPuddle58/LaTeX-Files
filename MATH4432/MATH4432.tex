%!TEX program = lualatex
\documentclass{article}
\usepackage{tcolorbox}
\usepackage{ntheorem}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{ulem}
\usepackage{graphicx}
\usepackage{centernot}
\usepackage{tikz}
\usepackage{tikz-cd}
\usepackage{tabularx}
\usepackage{makecell}
\usepackage{mathtools}
\usepackage[hidelinks, linktocpage]{hyperref}
\hypersetup{
    linktoc=all,
}

\usepackage[margin=1in]{geometry}
\usepackage[parfill]{parskip}

\everymath{\displaystyle}

\makeatletter
\newtheoremstyle{MyNonumberplain}%
  {\item[\theorem@headerfont\hskip\labelsep ##1\theorem@separator]}%
  {\item[\theorem@headerfont\hskip\labelsep ##3\theorem@separator]}%
\makeatother
\theoremstyle{MyNonumberplain}
\theorembodyfont{\upshape}

\theoremstyle{break}
\newtheorem*{proof}{Proof. }

\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\nin}{\not\in}
\newcommand{\p}{\phi}
\newcommand{\ev}{\mathbb{E}}
\newcommand{\var}{\text{Var}}
\newcommand{\der}{\operatorname{d\!}{}}
\newcommand{\evd}{\ev_{\mathcal{D}}}




\newtcolorbox{prfbox}{colback=gray!10,colframe=black!70,boxrule=0pt,arc=0pt,boxsep=2pt,left=2pt,right=2pt,leftrule=0pt}
\newtcolorbox{thmbox}{colback=orange!25,colframe=orange!85,boxrule=0pt,arc=0pt,boxsep=2pt,left=2pt,right=2pt,leftrule=2.5pt}
\newtcolorbox{defbox}{colback=blue!5,colframe=blue!70,boxrule=0pt,arc=0pt,boxsep=2pt,left=2pt,right=2pt,leftrule=2.5pt}
\newtcolorbox{ansbox}{colback=gray!10,colframe=black!70,boxrule=0pt,arc=0pt,boxsep=2pt,left=2pt,right=2pt,leftrule=0pt}
\newtcolorbox{expbox}{colback=green!10,colframe=green!70,boxrule=0pt,arc=0pt,boxsep=2pt,left=2pt,right=2pt,leftrule=2.5pt}
\newtcolorbox{warnbox}{colback=red!15,colframe=red!70,boxrule=0pt,arc=0pt,boxsep=2pt,left=2pt,right=2pt,leftrule=2.5pt}
\newtcolorbox{notebox}{colback=magenta!15,colframe=magenta!70,boxrule=0pt,arc=0pt,boxsep=2pt,left=2pt,right=2pt,leftrule=2.5pt}

\newtheorem{warning}{Warning}[section]
\newtheorem{remark}{Remark}[section]
\theoremstyle{break}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{example}{Example}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{note}{Note}

\theoremstyle{break}
%\theoremstyle{definition}
\theoremstyle{break}
\newtheorem{definition}{Definition}[section]

\title{MATH4432 Notes}
\author{SmokingPuddle58}

\begin{document}

\maketitle

\begin{center}
    This work is licensed under CC BY-NC-SA 4.0
\end{center}


\newpage

    This is the lecture note typed by SmokingPuddle in September, 2024. It mainly contains what professor mentions starting from year 3. For the contents of the first two weeks, I will try my best to include as much as possible. 

    The main reference source comes from the professor himself, lecture notes, tutorial notes, and also from the Internet if necessary.

    Please inform me if there is any errors, better within the semester or I will have a very high chance of forgetting the contents. 

    \bigskip


\begin{thmbox}
    Theorems, Corollary, Lemma, Proposition
\end{thmbox}

\begin{defbox}
    Definitions
\end{defbox}

\begin{expbox}
    Examples
\end{expbox}

\begin{warnbox}
    Warnings / Remarks
\end{warnbox}

\begin{prfbox}
    Proofs, Answers
\end{prfbox}

\begin{tabular}{ll}
    &\\
\end{tabular}

Some special symbols, notations and functions that will appear in this note:\bigskip

\begin{center}

    \begin{tabular}{|l|l|}
        \hline
        $\C$ & Set of complex numbers \\ \hline
        $\R$ & Set of real numbers \\ \hline
        $\Z$ & Set of integers \\ \hline
        $\Q$ & Set of rational numbers \\ \hline
    \end{tabular}
\end{center}
\begin{center}
    

\end{center}


\newpage

\tableofcontents

\newpage

% If you wish your section number begins from 1, remove / comment the line below
% \setcounter{section}{-1}

\section{Overview}

\subsection{Introduction}

Before we start, we shall clarify some of the notations that will be used.

Consider the following expression: $$P(X=x)$$

If we say $r.v.$ (Random variable) $X$, we actually means the name of the variable, while for $x$, we means the realization for such $r.v.$ 

Suppose we are now observing some quantitative response $Y$ and also input variable $X$, consisting of $p$ features, which can be expressed as:

$$
X=
    \begin{bmatrix}
        X_1 \\
        X_2 \\
        X_3 \\
        \vdots \\
        X_p
    \end{bmatrix}
$$

where $X_1,...,X_p$ are random variables. Then the relation between $Y$ and $X$ can be expressed as: 

$$
    Y=f(X)+\varepsilon
$$

where $\varepsilon$ is the error term independent from $X$, with mean 0, and $f$ is a deterministic function. We call such model the population level model, or ground truth model. (i.e. The number of samples is infinitely many)

\begin{warnbox}
    \begin{remark}
        Note that $Y,\varepsilon$ are all random variables, while $X$ is a collection of random variables.
    \end{remark}
\end{warnbox}

If we want to consider a sample level (the realization of the random variables), then the equation becomes:
    \begin{eqnarray*}
             y_i= & f(x_i)+\varepsilon_i & i=1,...,n
    \end{eqnarray*}

where $x_i$ can be a vector like the following:

$$
    x_i=
    \begin{bmatrix}
        {x_i}_1 \\
        {x_i}_2 \\
        {x_i}_3 \\
        \vdots \\
        {x_i}_p
    \end{bmatrix}
$$

and $n$ is the sample size.

\begin{warnbox}
    \begin{remark}
        In machine learning, vectors usually means \textbf{column vectors, but not row vectors}.
    \end{remark}
    For example, consider the equation $f(x)=a_1 x_1+a_2 x_2 + a_3 x_3$.
    If we know that 
    $
    a=    
    \begin{bmatrix}
        a_1 \\
        a_2 \\
        a_3
    \end{bmatrix}
    $,
        $
    x=    
    \begin{bmatrix}
        x_1 \\
        x_2 \\
        x_3
    \end{bmatrix}
    $,
    then $f(x)=a^\intercal x$, where $a^\intercal$ is the transpose of the vector $a$.
\end{warnbox}

Now let's go back to the ground truth model, which is $Y=f(X)+\varepsilon$. Suppose we want to construct $f$ from the data, then we will have: 
$$
    \hat{Y}=\hat{f}(X=x)
$$

for any observed $x$.

Suppose we are interested in the difference between the data and the observed prediction, then we will be interested in the value of $\ev(Y-\hat{Y})^2$, the expected square error.

\begin{warnbox}
    \begin{remark}
        Both $Y$ and $\hat{Y}$ are random variable, since $\hat{Y}$ is the prediction that is learnt from the data, and data comes from the random sample chosen from ground truth model. 
        Thus we are not interested in the value of $(Y-\hat{Y})^2$, since it is not fixed.
    \end{remark}
\end{warnbox}

\begin{thmbox}
    \begin{theorem}
    \begin{eqnarray*}
        \ev(Y-\hat{Y})^2 & = & \underbrace{\ev(f(X)-\hat{f}(X))^2}_{\text{Reducible}} \text{ } + \underbrace{\text{ Var}(\varepsilon)}_{\text{Irreducible}}
    \end{eqnarray*}
    \end{theorem}
    \begin{prfbox}
        \begin{proof}
            \begin{eqnarray*}
                \ev(Y-\hat{Y})^2 & = & \ev(f(X)+\varepsilon-\hat{f}(X))^2 \\
                                 & = & \ev(f(X)-\hat{f}(X)+\varepsilon)^2 \\
                                 & = & \ev((f(X)-\hat{f}(X))^2+2\varepsilon(f(X)-\hat{f}(X))+\varepsilon^2) \\
                                 & = & \ev((f(X)-\hat{f}(X))^2)+\ev(2\varepsilon(f(X)-\hat{f}(X)))+\ev(\varepsilon^2) \\
                                 & = & \ev((f(X)-\hat{f}(X))^2)+\underbrace{\ev(2\varepsilon)\ev((f(X)-\hat{f}(X)))}_{\substack{\text{Assume }\varepsilon \text{ independent from } \\ f,\hat{f}}}+\ev(\varepsilon^2) \\
                                 & = & \ev(f(X)-\hat{f}(X))^2+\underbrace{0}_{\substack{\ev(\varepsilon)=0}}+\ev(\varepsilon^2) 
            \end{eqnarray*}
            Since for any random variable $X$, and its expected value, $E(X)=\mu$, we have: (Covered in MATH2411)
            \begin{eqnarray*}
                \text{Var}(X) & = & \ev(X-\mu)^2\\
                              & = & \ev(X^2)+\ev(\mu^2)-2\ev(X\mu)\\
                              & = & \ev(X^2)+\mu^2-2\mu\ev(X)\\
                              & = & \ev(X^2)+\mu^2-2\mu^2\\
                              & = & \ev(X^2)-\mu^2
            \end{eqnarray*}
            Thus, 
            \begin{eqnarray*}
                \ev(Y-\hat{Y})^2 & = & \ev(f(X)-\hat{f}(X))^2+\ev(\varepsilon^2) \\
                                 & = & \ev(f(X)-\hat{f}(X))^2+\var(\varepsilon)
            \end{eqnarray*}
        \end{proof}
    \end{prfbox}
\end{thmbox}

To conclude, you can only reduce the error for the reducible part, by making your model approximate the ground truth model as well as possible, 
while we can really do not much on the irreducible part.

\subsection{Estimation of $f$}

There are two methods for estimating $f$, namely parametric, and non-parametric methods.

For parametric method, we assume that $f$ can be described by a set of parameters, such that once all of the parameters are known, then the model is known.

\begin{expbox}
    \begin{example}
        One of the most simple assumption is that $f$ is linear in $X$, which can be described as:  $$f(X)=\beta_0+\beta_1X_1+\beta_2X_2+...+\beta_pX_p$$
    \end{example}
\end{expbox}

For non-parametric method, we do not pre-specify the form of the model (Can be linear, non-linear. tree and neural network). To 
control the flexibility, we can always tune the parameters.

The advantages and disadvantages are listed in the following table.

\begin{table}[!h]
    \centering
    \begin{tabular}{|l|l|l|}
    \hline
                    & Parametric                                       & Non-parametric                                          \\ \hline
    Advantage    & Easy to solve and understand                     & More flexible and sometimes more powerful               \\ \hline
    Disadvantage & \makecell{The model may be too simple\\ to fit into the data} & \makecell{The model may be too flexible, \\there may be overfitting} \\ \hline
    \end{tabular}
\end{table}

\begin{center}
    \includegraphics*[scale=0.35]{img1.png}
\end{center}

\begin{table}[!h]
    \centering
    \begin{tabular}{|l|l|}
    \hline
    Ground truth model & Underfitting                         \\ \hline
    Good estimation    & Overfitting (Fitting into the noise) \\ \hline
    \end{tabular}
\end{table}

The above image shows the example of a ground truth model, a good estimation, overfitting and underfitting. It is also included in the lecture 
note. 

\subsection{Assessing Model Accuracy}

In statistical machine learning context, to find a good estimate $f$, we shall introduce the concept of regularization 
(Covered in detail later), in which we want to minimize the following value as much as possible:
$$\text{Loss}(Y,f)+\lambda R(f)$$
where $Y$ is the response, $\lambda$ is a tuning parameter (weight) for the regularizer $R(f)$ of the model $f$.

The introduction of the regularizer is trying to control the complexity / flexibility of the function $f$ to prevent perfect fit / overfitting issue.

\begin{expbox}
    \begin{example}[Spline interpolation]
        Consider the loss function and the regularizer as: $$\underbrace{\sum_{i=1}^{n_{\text{train}}}(y_i-g(x_i))^2}_{\text{Loss function}}+\lambda\underbrace{\int g''(t)^2\der t}_{\text{Regularizer}}$$
        \medskip
        The regularizer tries to control the second derivative of $g$ to be as small as possible to ensure smoothness.
        
        Assume that $\lambda$ is a extremely large value, the only solution is to let the integral to be 0, i.e. $g(t)$ should 
        be a linear function.
        \medskip

        If we put $\lambda=0$, then the solution will be $$\hat{g}(x_i)=y_i$$

        i.e. The model will have a perfect fit to the data.
        \medskip

        If we tune the parameter correctly, then we can get a good model that is neither overfit nor underfit.
    \end{example}
\end{expbox}

So how do we know if our tuning parameter is good or not?

Consider there is a set of data $\{(x_i,y_i)\}_{i=1...n}$, and we want to minimize $$\sum_{i=1}^{n}(y_i-g(x_i))^2+\lambda R(f)$$ as much as possible.

To achieve that, we need to spilt the data into two parts: Training data and Testing data, and the two set of datasets
should not be overlapping with each other.

The idea is, we only use the training data for solving optimization. After such process, we will 
obtain $\hat{g}$, which is estimated from the training data. The testing data is then used to evaluate whether the model is accurate or not. i.e. We would like to 
evaluate the value of $$\frac{1}{n}\sum_{i=1}^{n}(y_i-\hat{g}(x_i))^2$$
where $n$ is the number of testing data. Such value is defined as MSE (Mean Square Error).

\begin{defbox}
    \begin{definition}[Mean Square Error]
        $$MSE=\frac{1}{n}\sum_{i=1}^{n}(y_i-\hat{g}(x_i))^2$$ where $g(x_i)$ is 
        the prediction $\hat{g}$ gives for the $i-$th prediction.
    \end{definition}
\end{defbox}

\begin{center}
    \includegraphics*[scale=0.35]{img2.png}
\end{center}

\begin{table}[!h]
    \centering
    \begin{tabular}{|l|l|}
    \hline
    Black: Ground truth model & Red: Testing error                         \\ \hline
    Yellow: Simple linear model    & Gray: Training error \\ \hline
    Green: Perfect model (Fit all data into the model)    &  \\ \hline
    \end{tabular}
\end{table}

In the red curve, there are three point corresponding to the three different models on the left, which shows the MSE of overfitting
, underfitting and a good model. 

\begin{defbox}
    \begin{definition}[Training and Testing Error]
        Suppose $\hat{g}_\lambda$ is estimated from the data, and depends on $\lambda$, then the accuracy of $\hat{g}_\lambda$ based on the testing data is given by:
        $$\frac{1}{n_\text{Test}}\sum_{i\in\text{Test}}(y_i-\hat{g}_\lambda(x_i))^2$$
        This is called \textbf{testing mean square error (TMSE)}.

        \bigskip
        The \textbf{training error} is given by: $$\frac{1}{n_\text{Train}}\sum_{i\in\text{Train}}(y_i-\hat{g}_\lambda(x_i))^2$$
    \end{definition}
\end{defbox}

\begin{notebox}
    \begin{note}
        Training error is usually less than testing error, since optimization is solved with testing error, especially when you put $\lambda=0$.
    \end{note}
\end{notebox}

\begin{center}
    \includegraphics*[scale=0.35]{img3.png}
\end{center}

Note that linear regression above provides a very poor fit to the data, while perfect fit model 
does not increase error too much, since the noise is very small. 

\begin{center}
    \includegraphics*[scale=0.35]{img4.png}
\end{center}

For this dataset, the ground truth model is close to linear, and due to the large noise,
the high flexibility gives more error.

\newpage

\subsection{Bias-Variance Trade-Off}

As shown in the previous example, we can see that the testing error are in U-shape. To understand
the reason, we will need to introduce the concept of bias-variance trade-off.

Suppose we are interested in learning an unknown function $f(X)$ from the dataset $\mathcal{D}$,
namely $\hat{f}(X;\mathcal{D})$. Then at some future query point $X=x_0$, we want to
find $\hat{f}$, such that $\hat{f}$ satisfies: $$\min_{\hat{f}}[f(x_0)-\hat{f}(x_0;\mathcal{D})|X=x_0]^2$$

However are we really interested in evaluating this? Actually No! It is because the 
training dataset comes from a random selection! The prediction may not be accurate
if we changed another training dataset.

In order to solve the problem, we should take the random selection process in an \textbf{average sense}. 

Thus we are actually more interested in the following: $$\min_{\hat{f}}\evd[f(x_0)-\hat{f}(x_0;\mathcal{D})|X=x_0]^2$$

\begin{thmbox}
    \begin{theorem}
        \begin{eqnarray*}
            \evd[f(x_0)-\hat{f}(x_0;\mathcal{D})|X=x_0]^2&=&\underbrace{[f(x_0)-\evd(\hat{f}(x_0;\mathcal{D}))|X=x_0]^2}_{\text{Bias}^2}\\
            &+&\underbrace{\evd[[\evd(\hat{f}(x_0;\mathcal{D}))-\hat{f}(x_0;\mathcal{D})|X=x_0]^2]}_{\text{Variance}}
        \end{eqnarray*}
    \end{theorem}
    \begin{prfbox}
        \begin{proof}
            \begin{eqnarray*}
                [f(x_0)-\hat{f}(x_0,\mathcal{D})|X=x_0]^2 & = & [f(x_0)\underbrace{-\evd(\hat{f}(x_0;\mathcal{D}))+\evd(\hat{f}(x_0;\mathcal{D}))}_{=0}-\hat{f}(x_0,\mathcal{D})|X=x_0]^2\\
                &=& [f(x_0)-\evd(\hat{f}(x_0;\mathcal{D}))|X=x_0]^2 + [\evd(\hat{f}(x_0;\mathcal{D}))-\hat{f}(x_0,\mathcal{D})|X=x_0]^2\\
                &+& 2[f(x_0)-\evd(\hat{f}(x_0;\mathcal{D}))|X=x_0][\evd(\hat{f}(x_0;\mathcal{D}))-\hat{f}(x_0,\mathcal{D})|X=x_0]
            \end{eqnarray*}

            Now we take expectation to the expression above with respect to $\mathcal{D}$. We have:
            \begin{eqnarray*}
                &   &\evd[f(x_0)-\hat{f}(x_0,\mathcal{D})|X=x_0]^2\\
                & = & \underbrace{[f(x_0)-\evd(\hat{f}(x_0;\mathcal{D}))|X=x_0]^2}_{\text{Bias, as constant value}}\\
                & + & \underbrace{\evd\biggl([\evd(\hat{f}(x_0;\mathcal{D}))-\hat{f}(x_0,\mathcal{D})|X=x_0]^2\biggr)}_{\text{Variance}}\\
                & + & 2 \evd \biggl\{[f(x_0)-\evd(\hat{f}(x_0;\mathcal{D}))|X=x_0][\evd(\hat{f}(x_0;\mathcal{D}))-\hat{f}(x_0,\mathcal{D})|X=x_0]\biggr\}
            \end{eqnarray*}
            Consider the last term, we expand this term, then we will have: 
                \begin{eqnarray*}
                    && 2 \evd \biggl\{[f(x_0)-\evd(\hat{f}(x_0;\mathcal{D}))|X=x_0][\evd(\hat{f}(x_0;\mathcal{D}))-\hat{f}(x_0,\mathcal{D})|X=x_0]\biggr\} \\
                \end{eqnarray*}
        \end{proof}
    \end{prfbox}
\end{thmbox}

\begin{thmbox}
    \begin{prfbox}
        \begin{eqnarray*}
            &=& 2 \evd \biggl\{f(x_0)\evd[\hat{f}(x_0;\mathcal{D})]-f(x_0)\hat{f}(x_0;\mathcal{D})-[\evd[\hat{f}(x_0;\mathcal{D})]]^2+\hat{f}(x_0;\mathcal{D})\evd[\hat{f}(x_0;\mathcal{D})]\biggr\} \\
            &=& 2  \textcolor{red}{\Biggl\{}\evd\biggl\{f(x_0)\evd[\hat{f}(x_0;\mathcal{D})]\biggr\}-\evd\biggl\{f(x_0)\hat{f}(x_0;\mathcal{D})\biggr\}-\evd\biggl\{[\evd[\hat{f}(x_0;\mathcal{D})]]^2\biggr\} \\
            &+& \evd\biggl\{\hat{f}(x_0;\mathcal{D})\evd[\hat{f}(x_0;\mathcal{D})]\biggr\}\textcolor{red}{\Biggr\}}\\
            &=& \evd(f(x_0))\evd(\hat{f}(x_0;\mathcal{D}))-\evd(f(x_0))\evd(\hat{f}(x_0;\mathcal{D}))-\evd(\hat{f}(x_0;\mathcal{D}))^2+\evd(\hat{f}(x_0;\mathcal{D}))^2\\
            &=& 0
        \end{eqnarray*}
        The last term vanished, since we know that $\evd(f(x_0))=f(x_0)$ and $\evd(\evd(\hat{f}(x_0;\mathcal{D}))) = \evd(\hat{f}(x_0;\mathcal{D})).$

        \bigskip
        Also do note that even though $\hat{f}(X;\mathcal{D})$ is a random variable due to the randomness of the dataset, $\evd\hat{f}(X;\mathcal{D})$ is 
        no longer a random variable with respect to $\mathcal{D}$.

        \begin{expbox}
            \begin{example}
                If $Z\sim N(\mu,\sigma^2)$ is a random variable, then $\ev(Z)=\mu$ is no longer random variable.
            \end{example}
        \end{expbox}

    \end{prfbox}
\end{thmbox}

\begin{defbox}
    \begin{definition}[Bias and Variance]
        Consider
    \end{definition}
\end{defbox}

To be continued... [2024-09-12, 58:00]

\end{document}

% Below are some boxes that may help with your document. They are not rendered during compilation.

% Definition
\begin{defbox}
    \begin{definition}[]

    \end{definition}
\end{defbox}

% Theorem (With a proof box included, remove if necessary)
\begin{thmbox}
    \begin{theorem}

    \end{theorem}
    \begin{prfbox}
        \begin{proof}
            
        \end{proof}
    \end{prfbox}
\end{thmbox}

% Example
\begin{expbox}
    \begin{example}

    \end{example}
\end{expbox}

% Warning / Remarks
\begin{warnbox}
    \begin{warning}

    \end{warning}
\end{warnbox}

\begin{warnbox}
    \begin{remark}

    \end{remark}
\end{warnbox}

% Notes
\begin{notebox}
    \begin{note}

    \end{note}
\end{notebox}